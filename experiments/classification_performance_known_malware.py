import warnings
warnings.filterwarnings("ignore")
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
import experiments.functions as gv
PATH = "data/contextual_summaries/"
FILE_Train='training.csv'
FILE_Test='testing.csv'
NO_ROUNDS=10
df_train=pd.read_csv(PATH+FILE_Train)
df_test=pd.read_csv(PATH+FILE_Test)
ContextualSummary=pd.concat([df_train, df_test], ignore_index=True, sort=False)
CSfeatures=ContextualSummary.columns
CSfeatures=CSfeatures[2:] # remove CSID, LastFlowID
unique=['multiple_label','Source', 'Destination']
all=gv.pf_col_http+gv.hp_http+gv.up_col+gv.dp_col
all_https=gv.pf_col_https+gv.hp_https+gv.dp_col_https
feature_sets_names=['EarlyCrow','MADE','EarlyCrow_HTTPS','MADE_https']
feature_sets = [all,gv.MADE,all_https,gv.MADE_https]
label = ['label']
features =ContextualSummary[CSfeatures].copy(deep=True)
features = features.drop(label + unique, axis=1)
labels= ContextualSummary['label']
experiments=['botnet','APT','']
malware_type=['APT','botnet','Malicious']
for ex in experiments:
    for round_counter in range(0,NO_ROUNDS):
        train_features, test_features, train_labels, test_labels = train_test_split(
            features,
            pd.concat([ContextualSummary[unique], labels], axis=1),
            test_size=0.3)
        test_features = test_features[test_features.capture_type != ex]
        test_labels = ContextualSummary.iloc[test_features.index].label
        train_labels = train_labels.drop(unique, axis=1)
        fs_index = 0
        mal_type = malware_type[experiments.index(ex)]
        df_result_summary = pd.DataFrame(
            columns=['classifier','TN',   'FP'  ,  'FN'  ,  'TP',
                     'FPR', 'Pr_macro', 'R_macro', 'Acc', 'F1', 'F1_macro'])
        for fs in feature_sets:
                train_features_fs= train_features.loc[:, fs]
                test_features_fs= test_features.loc[:, fs]
                print("Experiment {}: Known {} vs. Legitimate. Round {}/10. Classifier: {}.".format(experiments.index(ex)+1,mal_type,round_counter+1,feature_sets_names[fs_index]), end='\r')
                clf = RandomForestClassifier(n_estimators=128, max_features='auto', random_state= 0)
                clf.fit(train_features_fs, train_labels)
                y_pred = clf.predict(test_features_fs)
                gv.results_summary(df_result_summary, fs_index,
                                feature_sets_names, test_labels, y_pred)
                fs_index += 1
        df_result_summary['FPR']=(df_result_summary.FP /(df_result_summary.FP +df_result_summary.TN))*100
        df_result_summary['FPR']=df_result_summary.FPR.astype(float)
        if round_counter == 0:
            df_result_average = df_result_summary.copy(deep=True)
        if round_counter >= 1:
            df_result_average.at[:, 1:] = (df_result_average.iloc[:,1:]*round_counter + df_result_summary.iloc[:,1:]) / (round_counter+1)
    df_result_average['FPR']=(df_result_average.FP /(df_result_average.FP +df_result_average.TN))*100
    df_result_average['FPR']=df_result_average.FPR.astype(float)
    df_result_average['FPR']=df_result_average['FPR'].round(2)
    df_result_average=df_result_average.drop(columns=['TN', 'FP', 'FN', 'TP'])
    print("-------------------------------------------------------------------")
    print("\t\t\t\t\t\tKnown {} vs. Legitimate".format(mal_type))
    print("-------------------------------------------------------------------")
    print(df_result_average)
print("Note: There is a possibility of fluctuating results due to the \nrandom split of train and test")
